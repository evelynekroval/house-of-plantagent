{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52665b4",
   "metadata": {},
   "source": [
    "# Experimenting with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9396ec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os # To manoeuver around files\n",
    "from dotenv import load_dotenv # To loads files from .env\n",
    "from urllib.parse import quote # To handle user input for URL\n",
    "\n",
    "# Sadly, following the LLM course is a lil out of date now, so the below won't make much sense...\n",
    "# from langchain.tools import WebBaseLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Let's instead go for agentic stuff directly\n",
    "from langchain.agents import create_agent\n",
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dataclasses import dataclass\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "load_dotenv() # Actually loading files from .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b7265",
   "metadata": {},
   "source": [
    "## Following the usual LLM course..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "219e7cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-8T\n",
      "sk-proj-8T\n"
     ]
    }
   ],
   "source": [
    "# Assign API Key from .env to a variable usable here\n",
    "openai_API_key = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "\n",
    "# Prints first 10 chars for loading confirmation\n",
    "print(openai_API_key[:10])\n",
    "print(OPENAI_API_KEY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06dc4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign API Key\n",
    "client = OpenAI(\n",
    "  api_key=openai_API_key\n",
    ")\n",
    "\n",
    "\n",
    "#Create a basic system prompt - TODO must import this from a separate file to modularise later.\n",
    "system_prompt = \"You are a vegan nutritionist. Focus on plantbased foods.\"\n",
    "\n",
    "\n",
    "# Creating the function\n",
    "def generate_text(prompt:str) -> str:\n",
    "    \"\"\"Used to get the main model reply\"\"\"\n",
    "    # Make API call\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        input=[\n",
    "                {\n",
    "                    \"role\": \"developer\",\n",
    "                    \"content\": system_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "        store=True,\n",
    "    )\n",
    "    # Prints out answer\n",
    "    print(response.output_text)\n",
    "\n",
    "# generate_text(\"Give me a 3-word sentence about eating meat.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b135e44",
   "metadata": {},
   "source": [
    "## LangChain Documentation\n",
    "### Creating an Agent\n",
    "#### System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change accordingly... \n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. \n",
    "If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27642ae7",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6285255",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497025e9",
   "metadata": {},
   "source": [
    "#### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c43960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = init_chat_model(\n",
    "    \"gpt-4.1\",\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=235\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5672a",
   "metadata": {},
   "source": [
    "#### Defining Response Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c53023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eff3f6",
   "metadata": {},
   "source": [
    "#### Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22d1e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d8cb4",
   "metadata": {},
   "source": [
    "#### Testing a Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9ef45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"Looks like the sun is on a roll in Florida—it's always sunny-side up! Don't forget your shades, unless you want to be egg-stra squinty.\", weather_conditions=\"It's always sunny in Florida!\")\n",
      "ResponseFormat(punny_response=\"No prob-llama! If you need more weather wisdom, just give me a shout—I'm always ready to rain down some forecasts!\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b13b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house-of-plantagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
